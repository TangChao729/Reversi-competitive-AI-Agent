# AI Method 4 - Monte Carlo Tree Search Plus Minimax [(Code)](https://github.com/COMP90054-2022S2/comp90054-a3-reversi-ai/blob/Wiki/agents/t_032/Agent_4.py)

# Table of Contents
- [Monte Carlo Tree Search Plus Minimax](#monte-carlo-tree-search-plus-minimax)
  * [Motivation](#motivation)
  * [Application](#application)
  * [Solved Challenges](#solved-challenges)
  * [Trade-offs](#trade-offs)
    - [*Advantages*](#advantages)
    - [*Disadvantages*](#disadvantages)
  * [Future improvements](#future-improvements)

## Monte Carlo Tree Search Plus Minimax

### Motivation  
Due to the 1 second time restriction and relatively large possible moves in early stage game, Monte Carlo Tree Search (MCTS) simulation times is often less than 50 times, which means that the result provided by the MCTS is unreliable and may be biased. Therefore, we considered to use a less time-consuming algorithms in the early stage of the game. Minimax agent that we developed previously provides a reliable action selection with less computation time requirements. As a result, we determined to use the Minimax in the early of stage of the game to overcome the shortcoming of the MCTS. This combination strategy of Minimax + MCTS further enhances the performance of our MCTS and become our final approach. 

[Back to top](#table-of-contents)

### Application  
The MiniMax part come from the AI-Method-2 and the MCTS part come from the AI-Method-3. The detailed strategy shown below:
1. Before the 20 moves of our current agent, if there is the corner position, return randomly from the corner position.
2. Before the 10 moves of our current agent, we will use the MiniMax to determine the best action.
3. If the move times of our current agent larger than 10 and there is no the corner position, we will use the MCTS to determined our best actions.

```python
    def SelectAction(self, actions, game_state):
        # The move numbers of current agent on the current board
        self.selection_times += 1

        # If there is only 1 action or "pass", directly return this action
        if len(actions) == 1:
            return actions[0]

        # Find whether the current action option contain the corner
        corner_location = {(0, 0), (0, 7), (7, 0), (7, 7)}
        corner_actions = list(set(actions).intersection(corner_location))

        # If there is corner action and move <= 20, directly return the corner action
        if self.selection_times <= 20 and len(corner_actions) > 0:
            return random.choice(corner_actions)

        # If number of move <= 10, using minimax
        elif self.selection_times <= 10:
            action, value = self.MiniMax(game_state, self.id, float('-inf'), float('inf'), 0)
            return action

        # If number of move > 10 and there is no the corner options, using MCTS
        else:
            return self.MCTS(game_state)
```
[Back to top](#table-of-contents)

### Solved Challenges
1.The timeout problem is already solved within the single MCTS algorithm and single minimax algorithm respectively.

2.We found in method 3 that pure MCTS often lose the game because they do not occupy the corner. Therefore, we add the corner strategy into this agent. However, the hard code corner strategy may influence the MCTS decision. By our experiment, if we use the corner strategy for all moves, the performance is even worse than only use MCTS. The reason may be the MCTS in the end of the game can choose a excellent actions better than the hard code of advantaged position. Therefore, the hard code strategy is only applied when the moves is less than 20 times (the early or middle stage of the game) and the performance is improved. Part of the code relevant to this strategy is shown below.

```python
        # Find whether the current action option contain the corner
        corner_location = {(0, 0), (0, 7), (7, 0), (7, 7)}
        corner_actions = list(set(actions).intersection(corner_location))

        # If there is corner action and move <= 20, directly return the corner action
        if self.selection_times <= 20 and len(corner_actions) > 0:
            return random.choice(corner_actions)
```

Here is a GIF to show this strategy. In this GIF, we can see the our agent(white) will take high priority to occupy the corner position. For the bottom left corner, our agent has the opportunity to occupy this corner, but it doesn't occupy at the beginning. The reason is the number of moves is more than 20 times for our agent and the MCTS can the choose better action than the bottom left corner. Finally, the MCTS + MiniMax won perfectly in this game.

![](https://github.com/COMP90054-2022S2/comp90054-a3-reversi-ai/blob/Wiki/wiki-template/images/hybrid_corner.gif)

[Back to top](#table-of-contents)


### Trade-offs  
#### *Advantages*  
1. This strategy combine the both advantage of the minimax and the MCTS. In detail, it takes the advantage of the minimax agent to provide reliable action in the early stage of the game and less computational power demanding. In addition, it takes advantage of MCTS that perform excellent at the middle and the end stage of the game due to the large amount of the simulation.
2. The hard code strategy encourage the agent to occupy the corner(the advantaged position on the game board) in the early or middle stage of the game which increase the probability of wining.

#### *Disadvantages*
1. In the middle stage of the game (move times 10-20), the MCTS will also face the poor performance problem due to the limited number of simulations(only 60-100 simulation times). This may result in the action is not optimal.
2. The heuristic function of the Minimax doesn't consider the mobility and stability. However, if we use the more complex heuristic function in the Minimax, the advantage of the less computation and time-consuming in the early stage of game may be sacrificed. Therefore, there is a trade-off between the effective and efficient of the heuristic function.

[Back to top](#table-of-contents)

### Future improvements  
1. The future improvements for this combination strategy could be the same as the future improvement of the MCTS implemented in the Method-3 and the Minimax implemented in the Method-2. Since this is the simple combination strategy that one algorithm response for one stage of the game, the improvement of the MCTS and minimax respectively is also useful for this combination strategy.
2. The middle stage(move times 10-20) of the MCTS is also face the no enough simulation times to support the excellent decision-making. Therefore, we also can choose an new strategy to determine the next action in the middle stage of the game.
3. Dynamically adjust the depth of minimax to maximize the depth of minimax while avoiding the problem of timeout.

[Back to top](#table-of-contents)