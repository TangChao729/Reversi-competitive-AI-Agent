# AI Method 1 - Breadth First Search [(Code)](https://github.com/COMP90054-2022S2/comp90054-a3-reversi-ai/blob/Wiki/agents/t_032/Agent_1.py)


# Table of Contents
- [Breadth First Search](#breadth-first-search)
  * [Motivation](#motivation)
  * [Application](#application)
  * [Solved challenges](#solved-challenges)
  * [Trade-offs](#trade-offs)     
     - [Advantages](#advantages)
     - [Disadvantages](#disadvantages)
  * [Future improvements](#future-improvements)

## Breadth First Search

### Motivation  
The breadth first search algorithm is an blind search algorithm used to find the best path and it is easy to be implemented. For the reversi game, we can set the end game state(both players cannot move) as the goal and find the best next action based on the highest score of the end game state. For the reversi game, there is a character that the players can rely on the last few steps of the game to change the current game state from loser to winner. The BFS can search about 15000 possible situations after 25 steps. Therefore, the BFS has the great potential to search a good next actions in near the end stage of the game and increase the probability to win the game.

The overview strategy of the BFS is to choose the best next action based on the highest score of the end state result. In additional to the pure BFS, the hard code strategy also adding in this agent to improve the performance of pure BFS strategy. The list of strategies is:
1. In general, choose the next action based on the highest end game state's score.
2. If there is outer corner that can be chosen, the outer corner has the highest priority to be chosen.
3. If there is stable position that can be chosen, the stable position has the higher priority to be chosen.
4. Avoid to choose the inner corner.

[Back to top](#table-of-contents)

### Application
The BFS algorithm is implemented by the double-ended queue(deque) and will simulate all possible actions of our agent until reach to the end game state. The best next action will be chosen best on the highest simulation score. Before using the BFS, the hard code strategy, such as the occupy the outer corner, occupy the stable position and avoid to occupy the inner corner, will be applied first. Those strategy will be detailed explained in next section.
```python
    def SelectAction(self, actions, game_state):
        # Init
        start_time = time.time()
        self.game_rule.agent_colors = game_state.agent_colors
        queue = deque([(game_state, [])])
        max_score = 0

        # Random choose and this solution is used when the bfs cannot search to the end state before the timeout
        random_actions = self.FilterAction(actions)
        if len(random_actions) == 1:
            return random_actions[0]
        solution = random.choice(random_actions)

        # If there is a stable_action, choose stable action.
        stable_action = self.find_stable_action(game_state, actions)
        if stable_action is not None:
            return stable_action

        # BFS
        while len(queue) and (time.time() - start_time < self.time_limit):
            state, path = queue.popleft()
            new_actions = self.FilterAction(self.GetActionList(state,self.id))
            
            # Only consider the our agent action
            for action in new_actions:
                if time.time() - start_time >= self.time_limit:
                    break
                next_path = path + [action]
                next_state, next_score = self.ExecuteAction(state, action, self.id)

                if self.game_rule.gameEnds and next_score > max_score:
                    max_score = next_score
                    solution = next_path[0]
                    continue
                 
                # The opponent move is based on the random
                opp_action = random.choice(self.GetActionList(next_state, 1- self.id))
                opp_state, opp_score = self.ExecuteAction(next_state, opp_action, 1-self.id)
                queue.append((opp_state, next_path))
        return solution
```


[Back to top](#table-of-contents)

### Solved Challenges
1. The timeout of the action selection is the largest challenge of the BFS. To solve this problem, we set the safe time limit is 0.95 and detected the timeout during the searching process. If the current time exceeds the safe time limit, it will break the while loop. If there is no solution provided by the BFS (which means that the BFS doesn't reach any end game state within the time limit) and there is no stable position or outer corner, the program will return a random solution.


2. The second challenges is to improve the BFS performance. Since BFS is a blind search method which cannot self-learning from the previous game or other game strategy. Therefore, there are some hard code strategy to improve the performance of the pure BFS and also improve the performance of random choice if there is no solution provided by the BFS.
   1. #### Outer corner & Inner Corner
   For the reversi game, the outer corner is the most important position of the game board since once the outer corner position is occupied, this position will not be flipped on the rest of the game. In addition, if the outer corner is occupied, the player is easy to flipped up opponent's edge and diagonal, which significantly increase the probability of winning. However, the inner corner is the position that cannot be occupied as much as possible. If one player occupied one inner corner in the early or middle game, it generally means that player will lose the outer corner close to that inner corner. 
   
      
    ```python
       def FilterAction(self, actions):
        outer_corner = {(0, 0), (0, 7), (7, 0), (7, 7)}
        inner_corner = {(1, 1), (1, 6), (6, 1), (6, 6)}
        
        # Find whether the candidate actions contains the outer corner
        sub_actions = list(set(actions).intersection(outer_corner))
        if len(sub_actions) > 0:
            actions = sub_actions
        
        # Filter out the inner corner from the candidate actions list
        sub_actions = list(set(actions).difference(inner_corner))
        if len(sub_actions) > 0:
            actions = sub_actions
        return actions
   ```
      Here is a short GIF to show this corner strategy <br>
      ![](https://github.com/COMP90054-2022S2/comp90054-a3-reversi-ai/blob/Wiki/wiki-template/images/corner.GIF)
        
   2. #### Stable position Strategy
        We define the stable position as follows: if once stable position is occupied, this piece cannot be flipped for the rest of the game. Therefore, the aim of this strategy is to find the stable position and increase the priorities to occupy the stable positions. In our implmentation, for one edge position we iteratively check the neighbours of this position. After placing this piece, in each direction (horizontal and vertical), if the neighbours of this position is the same color as the piece we are going to place, we check the neighbour this this neighbour. We iterate this process until we reach the corner of a board. If there is no false returned, it means that the original action would result in a stable piece.
   ```python
    def check_stability(self, game_state, action, start, end):
        sub_optimal = 0
        solution = None
        next_state, next_score = self.ExecuteAction(game_state, action, self.id)
        for i in range(start, end):
            if next_state.board[action[0]][i] != game_state.agent_colors[self.id]:
                return False
        if next_score > sub_optimal:
            sub_optimal = next_score
            solution = action
        return sub_optimal, solution

    def select_stable_action(self, stable_ans, best_optimal):
        best_solution = None
        if stable_ans is not False:
            sub_optimal, sub_solution = stable_ans
            if sub_optimal > best_optimal:
                best_solution = sub_solution
                best_optimal = sub_optimal
        return best_solution, best_optimal

    def find_stable_action(self, game_state, actions):
        best_optimal = float("-inf")
        best_solution = None
        for action in set(actions):
            if action[0] == 0 or action[0] == 7:
                stable_ans = self.check_stability(game_state, action, 0, action[1])
                best_solution, best_optimal = self.select_stable_action(stable_ans, best_optimal)

                stable_ans = self.check_stability(game_state, action, action[1], 8)
                best_solution, best_optimal = self.select_stable_action(stable_ans, best_optimal)

            if action[1] == 0 or action[1] == 7:
                stable_ans = self.check_stability(game_state, action, 0, action[0])
                best_solution, best_optimal = self.select_stable_action(stable_ans, best_optimal)

                stable_ans = self.check_stability(game_state, action, action[0], 8)
                best_solution, best_optimal = self.select_stable_action(stable_ans, best_optimal)

        return best_solution
    ```
    Here is a short GIF to show this stability strategy <br>
    ![](https://github.com/COMP90054-2022S2/comp90054-a3-reversi-ai/blob/Wiki/wiki-template/images/stability.GIF)

[Back to top](#images/table-of-contents)


### Trade-offs  
#### *Advantages*  
1. The BFS is easy to be implemented, which is a good start of the reversi AI.
2. The BFS can search the potential possible end game states as much as possible within the time limit to provide a reliable next action based on the largest score.
3. In the near the end stage of the game, the bfs can search more than 10000 possible end game states within 1 second, which can provide a excellent next action. This characteristic is important for the reversi game since the last few moves in Reversi game are the most critical moves. The score of the game state will change significantly in the last few moves and the situation of disadvantaged player wins the game by the last few moves is always happened.

#### *Disadvantages*
1. The time limited of each action selection is 1 seconds. However, in the early stage of the reversi game, the breadth first search algorithm may face the problem that it can only search few end game states, or even cannot search to the end of the game within the time limited, which means that in this situation, BFS cannot provide a valid best action.
2. The result provided by the BFS is not optimal and influenced by the random. It is impossible to search all the possible game state within 1 second. Therefore, the opponent move is chosen randomly during the simulation process. If the actual opponent doesn't move as expected, the action selected by BFS will be invalid.
3. The BFS is a kind of blind search algorithms and the performance is worse than that of the heuristic search in the reversi problem since the searching space is large and there are too many possible end game states of the current state.
4. The BFS algorithm cannot self-learning from the opponent or the previous game.

[Back to top](#table-of-contents)

### Future improvements  
1. Decrease the time complexity and remove the unnecessary steps during the process of searching to improve the search speed of BFS. This will allow the BFS to search more possible situation.
2. Currently, if the BFS doesn't search to the end state, it will return a random selection if the actions list doesn't contain the corner and stable edge. This can be improved by using better hard code strategy such as a weight matrix of the game board. If the BFS doesn't search to the end game state, it can return an actions with the highest weight.
3. In the early stage of game, the BFS is unreliable due to it cannot search to the end game state within the time limit. Therefore, the BFS can combine with other less time-consuming strategies to improve the performance. For example, using the minimax to determine the best next action in the early stage of game(such as the first ten choices) and using BFS in the remaining steps.

[Back to top](#table-of-contents)